# -Conversational-Voice-Assistant-using-Python-Ollama

 ğŸ“Œ Project Overview

This project is a voice-based conversational assistant built using Python.
The assistant listens to the userâ€™s voice, converts it into text, sends the conversation to a local AI model (Ollama), receives a response, and then speaks the response back to the user.

The assistant supports continuous conversation and remembers the context during a session.


 ğŸ¯ Objective of the Project

The main objectives of this project are:

* To understand speech-to-text (STT) and text-to-speech (TTS)
* To integrate local AI models (Ollama)
* To build a real-time conversational system
* To practice Python modules, functions, loops, and subprocess handling
* To create a hands-free AI assistant

 ğŸ› ï¸ Technologies & Libraries Used

# ğŸ”¹ Programming Language

* Python

# ğŸ”¹ Libraries

* `sounddevice` â†’ Captures microphone audio
* `speech_recognition` â†’ Converts speech to text
* `pyttsx3` â†’ Converts text to speech (offline)
* `subprocess` â†’ Communicates with Ollama AI model

# ğŸ”¹ AI Model

* Ollama (llama3) â€“ Local Large Language Model (LLM)


 âš™ï¸ System Requirements

* Python 3.x
* Ollama installed and running
* Microphone and speaker
* Internet (only for Google speech recognition)


 ğŸ§© Explanation of Code Components


# ğŸ”¹ 1. Text-to-Speech Setup

```python
tts = pyttsx3.init()
tts.setProperty("rate", 170)
```

Initializes the text-to-speech engine and sets the speaking speed.

# ğŸ”¹ 2. `listen_and_transcribe()` Function

Purpose:
Captures voice input and converts it into text.

Working:

* Records audio using the microphone
* Converts audio into text using Google Speech Recognition
* Returns recognized text
* Handles errors if speech is unclear



# ğŸ”¹ 3. `ask_ollama(conversation)` Function

Purpose:
Sends the conversation history to the Ollama AI model and gets a response.

Working:

* Uses `subprocess.run()` to execute the Ollama command
* Passes full conversation as input
* Receives AI-generated text output



# ğŸ”¹ 4. `speak(text)` Function

Purpose:
Converts AI-generated text into speech.

Working:

* Prints the response
* Uses `pyttsx3` to speak the response aloud



# ğŸ”¹ 5. Conversation History

```python
conversation_history = ""
```

Stores the entire conversation to maintain context, allowing the assistant to respond meaningfully in multi-turn conversations.


# ğŸ”¹ 6. `main()` Function

Purpose:
Controls the overall flow of the voice assistant.

Features:

* Starts the conversational assistant
* Continuously listens for user input
* Supports exit commands (`exit`, `stop`, `quit`)
* Maintains conversation history
* Calls AI and TTS functions


 ğŸ” Program Flow

```
User speaks
   â†“
Speech-to-Text conversion
   â†“
Conversation history updated
   â†“
Ollama AI generates response
   â†“
Text-to-Speech output
   â†“
Loop continues
```

 ğŸ§ª Sample Interaction

```
ğŸ¤ Speak now...
You: hello
ğŸ¤– Assistant: Hello! How can I help you today?

ğŸ¤ Speak now...
You: what is python
ğŸ¤– Assistant: Python is a high-level programming language...

ğŸ¤ Speak now...
You: exit
ğŸ¤– Assistant: Goodbye! Have a nice day.
```

 âœ… Key Features

* Voice-based interaction
* Continuous conversational chat
* Context-aware responses
* Offline AI processing (Ollama)
* No API key required
* Hands-free operation

 âš ï¸ Limitations

* Conversation history is temporary (lost after exit)
* Speech recognition depends on microphone quality
* Only one AI model supported at a time
* No GUI (command-line based)

 ğŸš€ Future Enhancements

* Permanent memory using files or database
* Wake word detection (e.g., â€œHey Assistantâ€)
* GUI interface
* Multiple language support
* Faster AI models

 ğŸ“ Conclusion

This project demonstrates how Python can be used to build a real-time conversational voice assistant by integrating speech processing and local AI models.
It is ideal for students learning full stack development, AI integration, and system-level programming.


